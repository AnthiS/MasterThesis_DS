{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition and Classification with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/named-entity-recognition-and-classification-with-scikit-learn-f05372f07ba2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataframe_ADE.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sentence_ID</th>\n",
       "      <th>Token_ID</th>\n",
       "      <th>BIO</th>\n",
       "      <th>POS</th>\n",
       "      <th>Token</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Gemcitabine-related</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>2</td>\n",
       "      <td>B_AdverseReaction</td>\n",
       "      <td>NN</td>\n",
       "      <td>radiation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>3</td>\n",
       "      <td>I_AdverseReaction</td>\n",
       "      <td>NN</td>\n",
       "      <td>recall</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>4</td>\n",
       "      <td>O</td>\n",
       "      <td>IN</td>\n",
       "      <td>in</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>5</td>\n",
       "      <td>O</td>\n",
       "      <td>DT</td>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Sentence_ID  Token_ID                BIO POS  \\\n",
       "0           0  Sentence: 1         1                  O  JJ   \n",
       "1           1  Sentence: 1         2  B_AdverseReaction  NN   \n",
       "2           2  Sentence: 1         3  I_AdverseReaction  NN   \n",
       "3           3  Sentence: 1         4                  O  IN   \n",
       "4           4  Sentence: 1         5                  O  DT   \n",
       "\n",
       "                 Token  ID  \n",
       "0  Gemcitabine-related   0  \n",
       "1            radiation   1  \n",
       "2               recall   2  \n",
       "3                   in   3  \n",
       "4                    a   4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     0\n",
       "Sentence_ID    0\n",
       "Token_ID       0\n",
       "BIO            0\n",
       "POS            0\n",
       "Token          0\n",
       "ID             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4271, 9211, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentence_ID'].nunique(), df.Token.nunique(), df.BIO.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BIO</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B_AdverseReaction</td>\n",
       "      <td>5749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I_AdverseReaction</td>\n",
       "      <td>6529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O</td>\n",
       "      <td>73832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 BIO  counts\n",
       "0  B_AdverseReaction    5749\n",
       "1  I_AdverseReaction    6529\n",
       "2                  O   73832"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('BIO').size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57693, 13527), (57693,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('BIO', axis=1)\n",
    "v = DictVectorizer(sparse=False)\n",
    "X = v.fit_transform(X.to_dict('records'))\n",
    "y = df.BIO.values\n",
    "\n",
    "\n",
    "classes = np.unique(y)\n",
    "classes = classes.tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=0)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1-- Epoch 1-- Epoch 1\n",
      "\n",
      "\n",
      "Norm: 7027.99, NNZs: 5199, Bias: 71.000000, T: 57693, Avg. loss: 336213515.283709Norm: 59866.79, NNZs: 5242, Bias: 42.000000, T: 57693, Avg. loss: 310400211.228624\n",
      "Total training time: 1.73 seconds.\n",
      "\n",
      "Total training time: 1.72 seconds.\n",
      "Norm: 66149.12, NNZs: 6908, Bias: -122.000000, T: 57693, Avg. loss: 599241534.155842\n",
      "Total training time: 1.93 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "      fit_intercept=True, max_iter=5, n_iter=None, n_iter_no_change=5,\n",
       "      n_jobs=-1, penalty=None, random_state=0, shuffle=True, tol=None,\n",
       "      validation_fraction=0.1, verbose=10, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per = Perceptron(verbose=10, n_jobs=-1, max_iter=5)\n",
    "per.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because tag “O” (outside) is the most common tag and it will make our results look much better than they actual are. So we remove tag “O” when we evaluate classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B_AdverseReaction', 'I_AdverseReaction']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_classes = classes.copy()\n",
    "new_classes.pop()\n",
    "new_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "B_AdverseReaction       0.00      0.00      0.00      1857\n",
      "I_AdverseReaction       0.08      1.00      0.14      2202\n",
      "\n",
      "        micro avg       0.08      0.54      0.14      4059\n",
      "        macro avg       0.04      0.50      0.07      4059\n",
      "     weighted avg       0.04      0.54      0.08      4059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=per.predict(X_test), y_true=y_test, labels=new_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['Token'].values.tolist(), \n",
    "                                                           s['POS'].values.tolist(), \n",
    "                                                           s['BIO'].values.tolist())]\n",
    "        self.grouped = self.data.groupby('Sentence_ID').apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_next(self):\n",
    "        try: \n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s \n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(df)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Gemcitabine-related', 'JJ', 'O'),\n",
       " ('radiation', 'NN', 'B_AdverseReaction'),\n",
       " ('recall', 'NN', 'I_AdverseReaction'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('a', 'DT', 'O'),\n",
       " ('patient', 'NN', 'O'),\n",
       " ('with', 'IN', 'O'),\n",
       " ('pancreatic', 'JJ', 'O'),\n",
       " ('cancer', 'NN', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we extract more features (word parts, simplified POS tags, lower/title/upper flags, features of nearby words) and convert them to sklearn-crfsuite format — each sentence should be converted to a list of dicts. The following code were taken from sklearn-crfsuites official site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0, \n",
    "        'word.lower()': word.lower(), \n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "    return features\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "B_AdverseReaction       0.77      0.73      0.75      1139\n",
      "I_AdverseReaction       0.79      0.73      0.76      1250\n",
      "\n",
      "        micro avg       0.78      0.73      0.76      2389\n",
      "        macro avg       0.78      0.73      0.76      2389\n",
      "     weighted avg       0.78      0.73      0.76      2389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels = new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What our classifier learned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "O      -> O       2.260939\n",
      "I_AdverseReaction -> I_AdverseReaction 1.529851\n",
      "B_AdverseReaction -> I_AdverseReaction 1.017486\n",
      "O      -> B_AdverseReaction 0.142104\n",
      "\n",
      "Top unlikely transitions:\n",
      "I_AdverseReaction -> O       -1.182713\n",
      "B_AdverseReaction -> O       -1.702729\n",
      "I_AdverseReaction -> B_AdverseReaction -4.136578\n",
      "B_AdverseReaction -> B_AdverseReaction -5.086790\n",
      "O      -> I_AdverseReaction -9.109015\n"
     ]
    }
   ],
   "source": [
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(4))\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation: It is very likely that the beginning of a geographical entity (B-geo) will be followed by a token inside geographical entity (I-geo), but transitions to inside of an organization name (I-org) from tokens with other labels are penalized hugely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the state features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "5.122251 B_AdverseReaction word.lower():eruption\n",
      "4.989512 O        BOS\n",
      "4.693180 B_AdverseReaction word.lower():teratogenic\n",
      "4.550998 B_AdverseReaction -1:word.lower():insulin-induced\n",
      "4.441654 B_AdverseReaction word.lower():vomiting\n",
      "4.257753 B_AdverseReaction word.lower():delirium\n",
      "4.172843 B_AdverseReaction +1:word.lower():formation\n",
      "4.006873 B_AdverseReaction word.lower():agitated\n",
      "3.894396 B_AdverseReaction word.lower():asystole\n",
      "3.886085 B_AdverseReaction word.lower():hepatotoxicity\n",
      "3.842604 B_AdverseReaction BOS\n",
      "3.823347 B_AdverseReaction word.lower():tics\n",
      "3.763621 B_AdverseReaction word.lower():nephrotoxicity\n",
      "3.741356 B_AdverseReaction word.lower():confusion\n",
      "3.541060 O        -1:word.lower():treat\n",
      "3.457861 B_AdverseReaction word.lower():discomfort\n",
      "3.389945 B_AdverseReaction word.lower():tremor\n",
      "3.385782 B_AdverseReaction word.lower():jaundice\n",
      "3.380567 B_AdverseReaction word.lower():cardiotoxicity\n",
      "3.336620 O        word.lower():leukemia\n",
      "3.287390 B_AdverseReaction word.lower():ascites\n",
      "3.255371 B_AdverseReaction word.lower():gangrene\n",
      "3.250794 O        word.lower():concentrations\n",
      "3.204905 I_AdverseReaction word.lower():pruritic\n",
      "3.181147 B_AdverseReaction word.lower():stuttering\n",
      "3.137954 B_AdverseReaction word.lower():ototoxicity\n",
      "3.102484 B_AdverseReaction +1:word.lower():malignant\n",
      "3.096695 B_AdverseReaction word.lower():confused\n",
      "3.081598 O        word.lower():diagnosis\n",
      "3.041855 B_AdverseReaction -1:word.lower():infliximab-induced\n",
      "\n",
      "Top negative:\n",
      "-1.970778 O        word.lower():fever\n",
      "-1.979364 O        word[-3:]:ema\n",
      "-2.000145 O        -1:word.lower():started\n",
      "-2.009744 O        word.lower():pain\n",
      "-2.012774 O        word.lower():prolonged\n",
      "-2.026216 O        -1:word.lower():delayed\n",
      "-2.046440 O        word.lower():cataract\n",
      "-2.075431 O        word[-3:]:hes\n",
      "-2.083281 O        word.lower():cough\n",
      "-2.097757 O        word[-3:]:thy\n",
      "-2.126099 O        word[-3:]:rgy\n",
      "-2.167621 O        word.lower():bleeding\n",
      "-2.169633 O        -1:word.lower():withdrawal\n",
      "-2.172230 O        word.lower():pneumonitis\n",
      "-2.195969 O        word.lower():damage\n",
      "-2.196049 O        -1:word.lower():painful\n",
      "-2.198557 O        word.lower():poisoning\n",
      "-2.208684 O        word[-3:]:gue\n",
      "-2.210543 O        word.lower():decreased\n",
      "-2.236699 O        +1:word.lower():eruption\n",
      "-2.262930 O        word.lower():ifosfamide-induced\n",
      "-2.312342 I_AdverseReaction -1:word.lower():life-threatening\n",
      "-2.394447 O        word[-2:]:ia\n",
      "-2.461119 O        word.lower():hemorrhage\n",
      "-2.478850 O        word.lower():swelling\n",
      "-2.574988 O        -1:word.lower():became\n",
      "-2.823201 O        word.lower():neurotoxicity\n",
      "-2.986673 B_AdverseReaction word.lower():chronic\n",
      "-3.076199 O        word.lower():fatal\n",
      "-3.122608 O        word.lower():seizures\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(30))\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.370614 B-per word.lower():president The model learns that token \"president\" is likely to be at the beginning of a person name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "    <div style=\"background-color: #fdd; padding: 0.5em;\">\n",
       "        Error: estimator CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False) is not supported\n",
       "    </div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "eli5.show_weights(crf, top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
